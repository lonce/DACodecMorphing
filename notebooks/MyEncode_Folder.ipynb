{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536ce3b-7d46-474c-aa71-f02e1a14c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd /app\n",
    "\n",
    "import os\n",
    "\n",
    "import dac\n",
    "from audiotools import AudioSignal\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6d14a-1cd4-4cc6-b427-444009e4b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bac65-041e-494f-b49e-647110129654",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_properties(0).total_memory/1e9\n",
    "device = torch.device('cuda') # if the docker was started with --gpus all, then can choose here with cuda:0 (or cpu)\n",
    "device\n",
    "\n",
    "torch.cuda.device_count()\n",
    "print(f'memeory on cuda 0 is  {torch.cuda.get_device_properties(0).total_memory/1e9}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312cbf31-aaa0-424a-9c5e-558b740bd2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = dac.utils.download(model_type=\"44khz\") \n",
    "model = dac.DAC.load(model_path)\n",
    "\n",
    "model.to(device); #wanna see the model? remove the semicolon\n",
    "model.eval();  # need to be \"in eval mode\" in order to set the number of quantizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8113df3a-e104-4b9b-9220-ce38167a91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def compress_wav_files(input_dir, output_dir, N_QUANTIZERS=9):\n",
    "    \"\"\"\n",
    "    Processes all .wav files from the input directory and writes the results with a .dac extension to the output directory.\n",
    "\n",
    "    Args:\n",
    "    input_dir (str): Directory containing .wav files.\n",
    "    output_dir (str): Directory where .dac files will be saved.\n",
    "    \"\"\"\n",
    "    # Check if output directory exists, create if not\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Iterate through all files in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            # Full path for input and output files\n",
    "            input_file = os.path.join(input_dir, filename)\n",
    "\n",
    "            signal = AudioSignal(input_file)\n",
    "            x = model.compress(signal, n_quantizers=N_QUANTIZERS)\n",
    "            \n",
    "\n",
    "            # Change the file extension from .wav to .dac\n",
    "            output_file = os.path.join(output_dir, os.path.splitext(filename)[0] + \".dac\")\n",
    "\n",
    "            # Save and load to and from disk\n",
    "            x.save(output_file)\n",
    "            \n",
    "            print(f\"Processed and saved {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "compress_wav_files('/scratch/dacdevdata/44kHz/N4/PisWinAppBee_sparse_recon', '/scratch/foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6c1bb-c1a1-4729-a52d-f459c35c0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "# load the file, and then \n",
    "with torch.no_grad():\n",
    "    dacfile = dac.DACFile.load(\"/scratch/foo/DSApplause--numClappers_exp-00.50.dac\")\n",
    "    \n",
    "    # FIRST - Decompress it back to an AudioSignal\\ from codes to z (1024) to signal   \n",
    "    print(f'dacfile.codes shape is: {dacfile.codes.shape}')\n",
    "    z_from_c, l_from_c,c =model.quantizer.from_codes(dacfile.codes.to(device))\n",
    "    print(f'z_from_c shape is: {z_from_c.shape}')\n",
    "    print(f'l_from_c shape is: {l_from_c.shape}')\n",
    "    print(f'c shape is: {c.shape}')\n",
    "    xTensor = model.decode(z_from_c)\n",
    "\n",
    "    # SECOND - Decompress directly using model.decompress   \n",
    "    yAudioSig = model.decompress(dacfile)  #an AudioSignal\n",
    "\n",
    "    \n",
    "print(f' The length of  xTensor  signal is {len(xTensor.cpu().detach().numpy()[0,0,:])}')\n",
    "print(f' The length of yAudioSig signal is {len(yAudioSig.cpu().detach().numpy()[0,0,:])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eead438-ac4a-45ce-b34b-9ebebdec5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsig=xTensor.cpu().detach().numpy()[0,0,:]\n",
    "plt.plot(xsig)\n",
    "ipd.Audio(xsig, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc109a-6d53-4f59-8047-d2c6254eced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ysig=yAudioSig.cpu().detach().numpy()[0,0,:]\n",
    "plt.plot(ysig)\n",
    "ipd.Audio(ysig, rate=44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e87e5b-11a1-4f0c-bc3b-d920eccd8740",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xsig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009136d2-a8f1-469a-97db-872eef693e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ysig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09516847-2be9-409f-91f3-df542a0c7c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
