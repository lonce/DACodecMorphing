{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016cce63-8622-42e0-918c-ae0b2909b6b7",
   "metadata": {},
   "source": [
    "In this notebook, we are interpolating between sounds in the \"z\" domain (1024D) - the space of the continuous latent space. The sounds are represented as a time series of latent vectors, to that means we are interpolating between different points in latent space at each point in time.  \n",
    "\n",
    "The results of this kind of interpolation in the latent space of the codec are not particularly interesting, and sound more like a cross fade (except for the amplitude variation which interpolates between the envelopes of the two sounds at each frame).  \n",
    "\n",
    "Still, it is interesting to see that the quantized space of the codec ( with (1024^9)^100 = 1024^900 = 10^1.8k is dense enough to handle this range of sounds and mixes with such high fidelity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae02cc-68a1-4cb8-a5f8-10ed9f5b41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE='cpu' # either 'cuda' or 'cpu'\n",
    "\n",
    "%pwd\n",
    "%cd /app\n",
    "\n",
    "import dac\n",
    "from audiotools import AudioSignal\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72176f9-2480-4b55-b2c2-115116e276c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "\n",
    "if DEVICE == 'cuda' : \n",
    "    torch.cuda.device_count()\n",
    "    torch.cuda.get_device_properties(0).total_memory/1e9\n",
    "    #torch.cuda.get_device_properties(1).total_memory/1e9\n",
    "    # device = torch.device(\"cuda:0\") # if the docker was started with --gpus all, then can choose here.\n",
    "    \n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "\n",
    "device = torch.device(DEVICE) # if the docker was started with --gpus all, then can choose here.\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163afb37-a4a6-42c5-a17b-550ff29b4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = dac.utils.download(model_type=\"44khz\") \n",
    "\n",
    "### This model doesn't sound as good - because it was trained on different data???\n",
    "#model_path = \"/scratch/codecs/codec.pth\" # /the default model from vampnet!\n",
    "model = dac.DAC.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2edd162-6d33-47e0-a777-9e614a4f789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device); #wanna see the model? remove the semicolon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9eb41-d1f9-4b6a-9b7b-f2ab54d8943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot=\"dacdevdata\" \n",
    "!ls ./{datadir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27dd96-78a4-44ba-94ab-ace01effca20",
   "metadata": {},
   "source": [
    "### <font color='blue'> Choose sn1 and snd2 for your morph. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580143a4-4e02-4dfa-b55f-537b7c8f5b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datadir=dataroot+\"/44kHz/N4/PisWinAppBee_sparse_recon\"\n",
    "\n",
    "snd1='/DSApplause--numClappers_exp-00.50.wav' \n",
    "snd2='/DSPistons--rate_exp-00.50.wav'\n",
    "#snd2='/DSBugs--busybodyFreqFactor-00.50.wav'\n",
    "#snd2='/DSWind--strength-00.50.wav'\n",
    "\n",
    "CORTADOFACTURA=1  #cut the wavefile lengths by this amount before loading so we don't overrun GPU memory\n",
    "\n",
    "#1) LOAD A SOUND\n",
    "wind = AudioSignal(datadir + snd1) # 2-second sound at 16kHz\n",
    "wind = wind[0,0,: int(wind.shape[2]/CORTADOFACTURA)] # cortado, otherwise the computation will bust memory\n",
    "\n",
    "#2) PUT IT ON THE GPU\n",
    "wind.to(model.device)\n",
    "#3) PREPROCESS (make sure sr agrees with model, i guess)\n",
    "wind_x = model.preprocess(wind.audio_data, wind.sample_rate)\n",
    "#4) ENCODE TO Z, C, and L\n",
    "with torch.no_grad():\n",
    "    wind_z, wind_codes, wind_latents, _, _ = model.encode(wind_x, n_quantizers=1) #model.encode(wind_x, 4)\n",
    "\n",
    "bee = AudioSignal(datadir + snd2) # 2-second sound at 16kHz\n",
    "bee = bee[0,0,: int(bee.shape[2]/CORTADOFACTURA)] # cortado, otherwise the computation will bust memory\n",
    "\n",
    "bee.to(model.device)\n",
    "bee_x = model.preprocess(bee.audio_data, bee.sample_rate)\n",
    "with torch.no_grad():\n",
    "    bee_z, bee_codes, bee_latents, _, _ = model.encode(bee_x, n_quantizers=1) # model.encode(bee_x, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09c75a-d506-4a64-9fa0-ba999a8b1eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'wind Audio Signal is shape {wind.shape}')\n",
    "print(f'wind_z shape is: {wind_z.shape}, and bee_z shape is: {bee_z.shape}')\n",
    "print(f'wind_codes shape is: {wind_codes.shape}, and bee_codes shape is: {bee_codes.shape}')\n",
    "print(f'wind_latents shape is: {wind_latents.shape}, and bee_latents shape is: {bee_latents.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1d698-a103-4b8d-9c2a-a5bf822b06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check a code vector to see if we are using the number specificied above\n",
    "wind_codes[0,:,40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b1f49-54a8-49c6-9284-1fa1fbda50c4",
   "metadata": {},
   "source": [
    "<div style=\"height: 10px; background-color: blue;\"></div>\n",
    "This next cell is just for reporting a bug do Descript.\n",
    "It also busts the GPU memory if audio is longer than about a second, so we comment it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd9307-f171-48c2-ae23-7da2f34dbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try to code the AudioSignal (wind_x) with diffenent number of quantizers\n",
    "# foo1_z, foo1_c, _, _, _ = model.encode(wind_x, n_quantizers=1)\n",
    "# foo4_z, foo4_c, _, _, _ = model.encode(wind_x, n_quantizers=4)\n",
    "# fooN_z, fooN_c, _, _, _ = model.encode(wind_x) # expected to use all 9 codebooks\n",
    "\n",
    "# print(f' Example code slices: \\n foo1_c: {foo1_c[0,:,40]} \\n foo4_c: {foo4_c[0,:,40]} \\n fooN_c: {fooN_c[0,:,40]}\\n')\n",
    "# print(f' And how about the z vectors that we will use to decode?\\n')\n",
    "# print(f' Are foo1_z and foo4_z tensors equal? Ans: {torch.equal(foo1_z, foo4_z)}')\n",
    "# print(f' Are foo1_z and fooN_z tensors equal? Ans: {torch.equal(foo1_z, fooN_z)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ad0a1-1bae-4ce3-982d-c077cbc58711",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    beerecon = model.decode(bee_z)\n",
    "\n",
    "beereconsignal = beerecon[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(beereconsignal)\n",
    "ipd.Audio(beereconsignal, rate=44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7dc6cb-cba4-44ad-ac59-88765adf4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    windrecon = model.decode(wind_z)\n",
    "\n",
    "windreconsignal = windrecon[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(windreconsignal)\n",
    "ipd.Audio(windreconsignal, rate=44100)\n",
    "\n",
    "#original \n",
    "#windsignal=wind.audio_data.cpu().detach().numpy()[0,0,:]\n",
    "#plt.plot(windsignal)\n",
    "#ipd.Audio(windsignal, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff44e2-eb67-47d4-a417-c4195219c414",
   "metadata": {},
   "source": [
    "### <font color='blue'> Choose a fixed interpolation value between the two sounds, or a continuous morph over the duration of the sounds. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ed628-39f3-4801-a4ac-cb82d766c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear INTERPOLATION between Bee and Wind\n",
    "\n",
    "#MORPHTYPE=\"FIXED_TWEEN\" #\"CONTINUOUS_MORPH\"\n",
    "MORPHTYPE=\"CONTINUOUS_MORPH\"\n",
    "\n",
    "if MORPHTYPE == \"CONTINUOUS_MORPH\" :\n",
    "    timesteps = bee_z.shape[2]  \n",
    "    # Generate linearly spaced values between 0 and 1\n",
    "    linear_values = torch.linspace(0, 1, timesteps, device=device)\n",
    "    # Reshape the linear_values tensor to match the shape of your tensor\n",
    "    linear_values = linear_values.view(1, 1, timesteps)\n",
    "    revlinear_values= 1-linear_values\n",
    "    print(f'CONTINUOUS_MORPH')\n",
    "\n",
    "else: \n",
    "    # Seems these don't have to sum to 1, but distorts if > 2, buzz if too small\n",
    "    linear_values = .5\n",
    "    revlinear_values = .5\n",
    "    print(f'FIXED_TWEEN')\n",
    "# OR just fixed interp point:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65813c5f-98af-4e0f-a71d-f278e21f4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_z = linear_values * wind_z + revlinear_values * bee_z\n",
    "print(f'shape of mix z is {mix_z.shape}')\n",
    "print(f'mix_z = {mix_z.min()}')\n",
    "print(f'max_z = {mix_z.max()}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = model.decode(mix_z) \n",
    "\n",
    "\n",
    "\n",
    "print(f'signal y.shape is {y.shape}') \n",
    "mix_signal = y[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(mix_signal)\n",
    "ipd.Audio(mix_signal, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2930a1b-3fc3-4cbe-a701-aefac56beac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
