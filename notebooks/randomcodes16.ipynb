{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefaf8a9-2d4d-42a4-8370-e7ebef023786",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd /app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c19df4-52ee-4991-b801-4fe691e49c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dac\n",
    "from audiotools import AudioSignal\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed366c-31cf-4370-a6c0-7c45072b1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1f43a-6a00-454e-9f18-8047b0c38bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a model\n",
    "model_path = dac.utils.download(model_type=\"16khz\")\n",
    "model = dac.DAC.load(model_path)\n",
    "model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31714d3d-9991-4401-99a2-0f3a46007d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata='dacdevdata/16kHz/orig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db664aa-0950-4e02-921c-a1e8287e320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls {pdata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15400d9-b250-486c-9614-e2db08adbc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio signal file\n",
    "signal = AudioSignal(pdata + '/DSPistons--rate_exp-00.00--x-02.wav') # 2-second sound at 16kHz\n",
    "signal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18440e12-7a0f-4715-a064-b93dc00e34cc",
   "metadata": {},
   "source": [
    "<div style=\"height: 6px; background-color: gray;\"></div>\n",
    "                      ** ORIGINAL **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75e54c-3956-4bf4-89ef-c4a80d7d8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal1=signal.audio_data.cpu().detach().numpy()[0,0,:]\n",
    "plt.plot(signal1)\n",
    "ipd.Audio(signal1, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79284569-e467-4378-8ca6-3c18a9d94617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode audio signal as one long file\n",
    "# (may run out of GPU memory on long files)\n",
    "signal.to(model.device)\n",
    "\n",
    "x = model.preprocess(signal.audio_data, signal.sample_rate)\n",
    "with torch.no_grad():\n",
    "    z, codes, latents, _, _ = model.encode(x)\n",
    "\n",
    "print(f'shapesare  x:{x.shape}, z:{z.shape}, codes:{codes.shape}, latents:{latents.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f518b69-6495-4a01-98a6-94740cfe5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try to code the AudioSignal (wind_x) with diffenent number of quantizers\n",
    "# # NOTE - this works for this 16kHz model, but notfor the 44kHz model (see morphlatents.ipynb)\n",
    "# foo1_z, foo1_c, _, _, _ = model.encode(x, n_quantizers=1)\n",
    "# foo4_z, foo4_c, _, _, _ = model.encode(x, n_quantizers=4)\n",
    "# fooN_z, fooN_c, _, _, _ = model.encode(x) # expected to use all 9 codebooks\n",
    "\n",
    "# print(f' Example code slices: \\n foo1_c: {foo1_c[0,:,40]} \\n foo4_c: {foo4_c[0,:,40]} \\n fooN_c: {fooN_c[0,:,40]}\\n')\n",
    "# print(f' And how about the z vectors that we will use to decode?\\n')\n",
    "# print(f' Are foo1_z and foo4_z tensors equal? Ans: {torch.equal(foo1_z, foo4_z)}')\n",
    "# print(f' Are foo1_z and fooN_z tensors equal? Ans: {torch.equal(foo1_z, fooN_z)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ee73f-f3a7-45b3-b341-6f224d8557cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode audio signal\n",
    "with torch.no_grad():\n",
    "    y = model.decode(z)\n",
    "print(f'shape of decoded y: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea7890d-0f7f-4d14-8996-5ed8f2bfc5ca",
   "metadata": {},
   "source": [
    "<div style=\"height: 6px; background-color: gray;\"></div>\n",
    "                      ** DECODED **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad5bec-cad1-48a4-957e-39801be8327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=y.cpu().detach().numpy()[0,0,:]\n",
    "plt.plot(y1)\n",
    "ipd.Audio(y1, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e52e91-3db8-441e-9a06-811c4c16bc1d",
   "metadata": {},
   "source": [
    "### <font color='green'> Since the original and reconstructed aren't exactly the same length, it is difficult to look at the difference between the two signals </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5de4f-c20f-48bc-8b3a-810c4a84ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffsig=y1-signal.audio_data.cpu().detach().numpy()[0,0,8:] # to match lengths!!\n",
    "plt.plot(diffsig)\n",
    "ipd.Audio(diffsig, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afac0e6-0c67-470c-a47d-520216d884a6",
   "metadata": {},
   "source": [
    "### <font color='green'> Compress/decompress go to/from .dac files and signals </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66aeaa0-7a59-4516-87e4-5add6015588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, use the `compress` and `decompress` functions\n",
    "# to compress long files.\n",
    "\n",
    "signal = signal.cpu()\n",
    "x_compressed = model.compress(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ecd1ae-e45c-4e9b-8a9e-45e57e021bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load to and from disk\n",
    "x_compressed.save(\"/tmp/compressed.dac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58878149-619a-41b3-8d1d-b34b76d9f58f",
   "metadata": {},
   "source": [
    "<div style=\"height: 6px; background-color: gray;\"></div>\n",
    "                      ** decompressed DAC **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643e4eb-a33d-41a6-b932-b15391981cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_loaded = dac.DACFile.load(\"/tmp/compressed.dac\")\n",
    "y2 = model.decompress(x_loaded)\n",
    "y3=y2.cpu().detach().numpy()[0,0,:]\n",
    "plt.plot(y3)\n",
    "ipd.Audio(y3, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a2f08c-a7d3-43f6-9b63-17974984b4a3",
   "metadata": {},
   "source": [
    "<div style=\"height: 10px; background-color: blue;\"></div>\n",
    "<font size=14, color='blue'> Randomizing codebook entries </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0535020-af31-4c10-bc34-df8a1340c2fb",
   "metadata": {},
   "source": [
    "### <font color='green'> Lets try to look at just a short excerpt of codes and the signal it would make. Dimensions are (B, Nq, T) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606fde7e-0732-4cff-954b-9f3bd0abb9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2455f4-cfa8-4819-a5d4-5320326a8937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I must admit, I don't really know how chunk_length and original_length should be set,\n",
    "# and how numframes (number of code vectors) plays with all that. Errors arise if they don't fit. \n",
    "\n",
    "lengthfactor=12\n",
    "\n",
    "numframes=25*lengthfactor\n",
    "chunklength=60  #this seems to work for most length factors > 4\n",
    "olength=2466*lengthfactor+1\n",
    "\n",
    "numcodes=4 #I think 12 is the max the codec supports, can be as small as 1\n",
    "\n",
    "baz = torch.randint(low=1010, high=1013, size=(1, numcodes, numframes)) #between 0 and 1023\n",
    "\n",
    "my_dac_file = dac.DACFile(\n",
    "            codes=baz,\n",
    "            chunk_length=chunklength,\n",
    "            original_length=olength,\n",
    "            input_db=-20,\n",
    "            channels=1,\n",
    "            sample_rate=16000,\n",
    "            padding=False,\n",
    "            dac_version='1.0.0',\n",
    "        )\n",
    "#my_dac_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124d866-9874-4288-8c87-c1e9ff658eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this sounds like .....\n",
    "ydcompress = model.decompress(my_dac_file)\n",
    "ysig=ydcompress.cpu().detach().numpy()[0,0,:]\n",
    "plt.plot(ysig)\n",
    "ipd.Audio(ysig, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354501c7-378c-4dfa-8a1e-34708712da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets string a bunch of them together.....\n",
    "\n",
    "sbuf=[]\n",
    "sdur=1 # second\n",
    "for x in range(8,30):\n",
    "    my_dac_file.codes=torch.randint(low=1010-10*x, high=1013-10*x, size=(1, numcodes, numframes))\n",
    "    #SAVE my_dac_file.codes=torch.randint(low=1010-4*x, high=1013-3*x, size=(1, numcodes, numframes))\n",
    "    #SAVE my_dac_file.codes=torch.randint(low=1000-x, high=1003-x, size=(1, numcodes, numframes))\n",
    "    ydcompress = model.decompress(my_dac_file)\n",
    "    ysig=ydcompress.cpu().detach().numpy()[0,0,:]\n",
    "    # ipd.Audio(audio_segment, rate=44100, autoplay=True)\n",
    "    # time.sleep(sdur+.1)\n",
    "    sbuf.extend(ysig)\n",
    "\n",
    "print(f'sbuf.len={len(sbuf)}', flush=True)\n",
    "plt.plot(ysig)\n",
    "ipd.Audio(sbuf, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da649a-e5c8-4576-81e6-00a67a13d15c",
   "metadata": {},
   "source": [
    "### <font color='green'> OK, so some different kinda fun. Randomize code book indexes! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fe8c3-577f-40f1-908c-377063bf0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcodes = torch.randint(0, 3, size=(1, 12, 204))\n",
    "#rcodes = torch.ones( size=(1, 12, 204), dtype=torch.int64)*555\n",
    "rcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7cfba6-1d9c-4133-87ae-e81599a18bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = dac.DACFile.load(\"/tmp/compressed.dac\")\n",
    "foo.codes=rcodes\n",
    "ydcompress = model.decompress(foo)\n",
    "ysig=ydcompress.cpu().detach().numpy()[0,0,:]\n",
    "plt.plot(ysig)\n",
    "ipd.Audio(ysig, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89933a-17a4-4cc9-b4c7-fe33bbe4eff6",
   "metadata": {},
   "source": [
    "### <font color='green'> Well, THAT is pretty interesting for a \"universal decoder\" - when the code indexes are random, we get something that sounds like a noisy babling male voice!!!!!! </font>  \n",
    "\n",
    "\n",
    "Now for other systematic manipulations..... they all sound like babblin male voices....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d1ac0-f5a4-484b-871b-422f43e01bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entries in the column dimension contain their depth index\n",
    "\n",
    "depth = 204   # Number of depth slices\n",
    "rows = 1    # Number of rows (one row)\n",
    "cols = 12    # Number of columns\n",
    "\n",
    "# Generate depth indices using torch.arange()\n",
    "depth_indices = torch.arange(depth).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "# Broadcast depth indices to match the desired shape\n",
    "broadcasted_indices = depth_indices.expand(rows, cols, -1)\n",
    "\n",
    "# Create the final 3D tensor\n",
    "result_tensor = broadcasted_indices*4\n",
    "\n",
    "print(result_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf456b-341e-4fcc-8de9-25a2d887a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = dac.DACFile.load(\"/tmp/compressed.dac\")\n",
    "foo.codes=result_tensor  ###############################\n",
    "ydcompress = model.decompress(foo)\n",
    "ysig=ydcompress.cpu().detach().numpy()[0,0,:]\n",
    "plt.plot(ysig)\n",
    "ipd.Audio(ysig, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df068751-8c52-4417-a4db-51d4fca9de6e",
   "metadata": {},
   "source": [
    "<div style=\"height: 10px; background-color: blue;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f82ec-bf15-4985-8903-6d07d3ece4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
