{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016cce63-8622-42e0-918c-ae0b2909b6b7",
   "metadata": {},
   "source": [
    "In this notebook, we are interpolating between sounds in the \"z\" domain - the space of the continuous latent space. The sounds are represented as a time series of latent vectors, to that means we are interpolating between different points in latent space at each point in time.  \n",
    "\n",
    "The results of this kind of interpolation in the latent space of the codec are not particularly interesting, and sound more like a cross fade (except for the amplitude variation which interpolates between the envelopes of the two sounds at each frame).  \n",
    "\n",
    "Still, it is interesting to see that the quantized space of the codec ( with (1024^9)^100 = 1024^900 = 10^1.8k is dense enough to handle this range of sounds and mixes with such ghigh fidelity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ae02cc-68a1-4cb8-a5f8-10ed9f5b41c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd /app\n",
    "\n",
    "import dac\n",
    "from audiotools import AudioSignal\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72176f9-2480-4b55-b2c2-115116e276c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_properties(0).total_memory/1e9\n",
    "torch.cuda.get_device_properties(1).total_memory/1e9\n",
    "device = torch.device(\"cuda:0\") # if the docker was started with --gpus all, then can choose here.\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163afb37-a4a6-42c5-a17b-550ff29b4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = dac.utils.download(model_type=\"44khz\") \n",
    "\n",
    "### This model doesn't sound as good - because it was trained on different data???\n",
    "# model_path = \"/scratch/codecs/codec.pth\" # /the default model from vampnet!\n",
    "\n",
    "model = dac.DAC.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76af5bf5-5bb0-4a8c-bea8-a78672a033c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDNN VERSION: 8500\n",
      "__Number CUDA Devices: 2\n",
      "__CUDA Device Name: NVIDIA GeForce RTX 3090\n",
      "__CUDA Device Total Memory [GB]: 25.447170048\n"
     ]
    }
   ],
   "source": [
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2edd162-6d33-47e0-a777-9e614a4f789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device); #wanna see the model? remove the semicolon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab9eb41-d1f9-4b6a-9b7b-f2ab54d8943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot=\"/scratch/dacdevdata\" \n",
    "# !ls {datadir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580143a4-4e02-4dfa-b55f-537b7c8f5b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/audiotools/core/audio_signal.py:501: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data, sample_rate = librosa.load(\n",
      "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/dacdevdata/44kHz/N4/PisWinAppBee_sparse_recon/DSApplause--numClappers_exp-00.50.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/scratch/dacdevdata/44kHz/N4/PisWinAppBee_sparse_recon/DSApplause--numClappers_exp-00.50.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m CORTADOFACTURA\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m#cut the wavefile lengths by this amount before loading so we don't overrun GPU memory\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#1) LOAD A SOUND\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m snd1 \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSignal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatadir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msnd1_wav\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 2-second sound at 16kHz\u001b[39;00m\n\u001b[1;32m     14\u001b[0m snd1 \u001b[38;5;241m=\u001b[39m snd1[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,: \u001b[38;5;28mint\u001b[39m(snd1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m/\u001b[39mCORTADOFACTURA)] \u001b[38;5;66;03m# cortado, otherwise the computation will bust memory\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#2) PUT IT ON THE GPU\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiotools/core/audio_signal.py:154\u001b[0m, in \u001b[0;36mAudioSignal.__init__\u001b[0;34m(self, audio_path_or_array, sample_rate, stft_params, offset, duration, device)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstft_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m audio_array \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sample_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust set sample rate!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/audiotools/core/audio_signal.py:501\u001b[0m, in \u001b[0;36mAudioSignal.load_from_file\u001b[0;34m(self, audio_path, offset, duration, device)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads data from file. Used internally when AudioSignal\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;124;03mis instantiated with a path to a file.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    AudioSignal loaded from file\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m data, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmono\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m data \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mensure_tensor(data)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[1;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/util/decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    236\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[1;32m    242\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/dacdevdata/44kHz/N4/PisWinAppBee_sparse_recon/DSApplause--numClappers_exp-00.50.wav'"
     ]
    }
   ],
   "source": [
    "datadir=dataroot+\"/44kHz/N4/PisWinAppBee_sparse_recon\"\n",
    "\n",
    "N_QUANTIZERS = 9  ## SEEMS TO HAVE NO EFFECT - I guess because it is a property of the pretrained model?\n",
    "\n",
    "snd1_wav ='/DSApplause--numClappers_exp-00.50.wav' \n",
    "#snd1_wav='/DSPistons--rate_exp-00.50.wav'\n",
    "snd2_wav = '/DSBugs--busybodyFreqFactor-00.50.wav'\n",
    "#snd2_wav ='/DSWind--strength-00.50.wav'\n",
    "\n",
    "CORTADOFACTURA=3  #cut the wavefile lengths by this amount before loading so we don't overrun GPU memory\n",
    "\n",
    "#1) LOAD A SOUND\n",
    "snd1 = AudioSignal(datadir + snd1_wav) # 2-second sound at 16kHz\n",
    "snd1 = snd1[0,0,: int(snd1.shape[2]/CORTADOFACTURA)] # cortado, otherwise the computation will bust memory\n",
    "\n",
    "#2) PUT IT ON THE GPU\n",
    "snd1.to(model.device)\n",
    "#3) PREPROCESS (make sure sr agrees with model, i guess)\n",
    "snd1_x = model.preprocess(snd1.audio_data, snd1.sample_rate)\n",
    "#4) ENCODE TO Z, C, and L\n",
    "snd1_z, snd1_codes, snd1_latents, _, _ = model.encode(snd1_x, N_QUANTIZERS) #model.encode(snd1_x, 4)\n",
    "\n",
    "snd2 = AudioSignal(datadir + snd2_wav) # 2-second sound at 16kHz\n",
    "snd2 = snd2[0,0,: int(snd2.shape[2]/CORTADOFACTURA)] # cortado, otherwise the computation will bust memory\n",
    "\n",
    "snd2.to(model.device)\n",
    "snd2_x = model.preprocess(snd2.audio_data, snd2.sample_rate)\n",
    "snd2_z, snd2_codes, snd2_latents, _, _ = model.encode(snd2_x, N_QUANTIZERS) # model.encode(snd2_x, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09c75a-d506-4a64-9fa0-ba999a8b1eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'snd1 Audio Signal is shape {snd1.shape}')\n",
    "print(f'snd1_z shape is: {snd1_z.shape}, and snd2_z shape is: {snd2_z.shape}')\n",
    "print(f'snd1_codes shape is: {snd1_codes.shape}, and snd2_codes shape is: {snd2_codes.shape}')\n",
    "print(f'snd1_latents shape is: {snd1_latents.shape}, and snd2_latents shape is: {snd2_latents.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1d698-a103-4b8d-9c2a-a5bf822b06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check a code vector to see if we are using the number specificied above\n",
    "snd1_codes[0,:,40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b1f49-54a8-49c6-9284-1fa1fbda50c4",
   "metadata": {},
   "source": [
    "<div style=\"height: 10px; background-color: blue;\"></div>\n",
    "This next cell is just for reporting a bug do Descript.\n",
    "It also busts the GPU memory if audio is longer than about a second, so we comment it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd9307-f171-48c2-ae23-7da2f34dbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try to code the AudioSignal (snd1_x) with diffenent number of quantizers\n",
    "# foo1_z, foo1_c, _, _, _ = model.encode(snd1_x, n_quantizers=1)\n",
    "# foo4_z, foo4_c, _, _, _ = model.encode(snd1_x, n_quantizers=4)\n",
    "# fooN_z, fooN_c, _, _, _ = model.encode(snd1_x) # expected to use all 9 codebooks\n",
    "\n",
    "# print(f' Example code slices: \\n foo1_c: {foo1_c[0,:,40]} \\n foo4_c: {foo4_c[0,:,40]} \\n fooN_c: {fooN_c[0,:,40]}\\n')\n",
    "# print(f' And how about the z vectors that we will use to decode?\\n')\n",
    "# print(f' Are foo1_z and foo4_z tensors equal? Ans: {torch.equal(foo1_z, foo4_z)}')\n",
    "# print(f' Are foo1_z and fooN_z tensors equal? Ans: {torch.equal(foo1_z, fooN_z)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba94311e-151f-4d86-a185-9e3f387639ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Project Latents Experiment!!!!!!!!!!!!!!!!!\n",
    "### Lets just do a reality check that if we \"manually\" take the 8D latents to 1024D z and then decode, \n",
    "### it should be the same as the z we got from model encode.\n",
    "\n",
    "snd2_z_from_l,_,_ = model.quantizer.from_latents(snd2_latents)\n",
    "print(f'snd2_z_from_l shape is: {snd2_z_from_l.shape}')\n",
    "torch.dist(snd2_z_from_l, snd2_z, p=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4582067-5a1a-4f37-ae47-5d5da0d3f1d7",
   "metadata": {},
   "source": [
    "### <font color='blue'> First decode both sounds a play them </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ad0a1-1bae-4ce3-982d-c077cbc58711",
   "metadata": {},
   "outputs": [],
   "source": [
    "snd2recon = model.decode(snd2_z_from_l) #z_from_l or z from encode are the same\n",
    "\n",
    "snd2reconsignal = snd2recon[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(snd2reconsignal)\n",
    "ipd.Audio(snd2reconsignal, rate=44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8e7d5-8f3a-4924-8d6c-6060cf152935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7dc6cb-cba4-44ad-ac59-88765adf4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "snd1recon = model.decode(snd1_z)\n",
    "\n",
    "snd1reconsignal = snd1recon[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(snd1reconsignal)\n",
    "ipd.Audio(snd1reconsignal, rate=44100)\n",
    "\n",
    "#original \n",
    "#snd1signal=snd1.audio_data.cpu().detach().numpy()[0,0,:]\n",
    "#plt.plot(snd1signal)\n",
    "#ipd.Audio(snd1signal, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5083fe2-9949-44c3-b273-d8241275efae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3000ab-7646-40ff-a105-8431023e6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def assign_values_with_mask(value, v2, mask):\n",
    "#     # Ensure v2 and mask have the same length\n",
    "#     assert len(v2) == len(mask), \"v2 and mask must have the same length\"\n",
    "\n",
    "#     # If v1 is a single number, expand it to have the same shape as v2\n",
    "#     if isinstance(value, (int, float)):\n",
    "#         v1 = torch.full_like(v2, value)\n",
    "#     else :\n",
    "#         print('error: first arg must be a float or int to fill vector where mask is `True`')\n",
    "\n",
    "#     # Use the mask to assign values from v1 to v2\n",
    "#     result = torch.where(mask, v1, v2)\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aeb9e0-c7c0-49f5-ae1d-7094dbe5a560",
   "metadata": {},
   "source": [
    "### <font color='blue'> Now do n interpolation in the *latent* space (the latent space is the \"projected\" space and has only 8 dimensions for each codebook) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ed628-39f3-4801-a4ac-cb82d766c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"morph\" between two time-indexed sequences of latent variables\n",
    "# Interpoloates between i1*va+(1-i1)vb to i2*va+(1-i2)vb\n",
    "def interp(va, vb, i1, i2) : \n",
    "    assert va.shape == vb.shape, \"Tensors must have the same shape\"\n",
    "    timesteps=va.shape[2]\n",
    "    linear_values = torch.linspace(i1, i2, timesteps, device=device)\n",
    "    complementlinear_values = 1-linear_values \n",
    "\n",
    "    return linear_values * va + complementlinear_values * vb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3ed75-146f-4ae3-8538-67c03434994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# la=snd2_latents\n",
    "# lb=snd1_latents\n",
    "# linterp=interp(la, lb, .6, .4)  ##Interpolate in the 8D projected space!\n",
    "# print(f'linterp.shape is {linterp.shape}') \n",
    "\n",
    "# z_from_l,_,_ = model.quantizer.from_latents(linterp)\n",
    "# y = model.decode(z_from_l)\n",
    "# print(f'signal y.shape is {y.shape}') \n",
    "# mix_signal = y[0,0,:].cpu().detach().numpy()\n",
    "# plt.plot(mix_signal)\n",
    "# ipd.Audio(mix_signal, rate=44100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb8686-b19d-49a3-b283-2f0d35d865c4",
   "metadata": {},
   "source": [
    "### <font color='blue'> Now rather than interpolating in latent space, swap value in the dimensions with even index. Each sound is now made up of latents where have the values come from one sound, half the values from the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e5f1a-c6da-4f1f-b765-2008500b1908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the latent variable at each time step, \n",
    "#and swaps their invidual values in the dimensions with an even index\n",
    "# Thus each matrix at each time step has half its values from one sound,\n",
    "# and the other half from the other. \n",
    "\n",
    "# does this in place - modifies the original matrices\n",
    "def swap_elements_for_even_n(matrix1, matrix2):\n",
    "    # Get the shape of the input matrices\n",
    "    _, n, m = matrix1.size()\n",
    "\n",
    "    # Create masks for even and odd indices along the n dimension\n",
    "    even_mask = torch.arange(n) % 2 == 1  # Indices where n is even\n",
    "    odd_mask = torch.arange(n) % 2 == 0   # Indices where n is odd\n",
    "\n",
    "    # Select elements where n is even from both matrices\n",
    "    even_elements_matrix1 = matrix1[:, even_mask, :]\n",
    "    even_elements_matrix2 = matrix2[:, even_mask, :]\n",
    "\n",
    "    # Swap the even elements between the matrices\n",
    "    matrix1[:, even_mask, :] = even_elements_matrix2\n",
    "    matrix2[:, even_mask, :] = even_elements_matrix1\n",
    "\n",
    "    return matrix1, matrix2\n",
    "\n",
    "## test\n",
    "# a= torch.rand(1, 4, 2)\n",
    "# b= torch.rand(1, 4, 2)\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print('--------')\n",
    "# swap_elements_for_even_n(a, b)\n",
    "# print(a)\n",
    "# print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c64a7f-4391-42bd-bd3e-63932b2c2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "la=snd2_latents\n",
    "lb=snd1_latents\n",
    "# first do a swap of values in the latent space for even-numbered dimensions\n",
    "la, lb = swap_elements_for_even_n(la, lb)\n",
    "linterp=interp(la, lb, 0, 0)  ## (0,0 plays the first sound only, 1,1 plays the second sound only)\n",
    "print(f'linterp.shape is {linterp.shape}') \n",
    "\n",
    "z_from_l,_,_ = model.quantizer.from_latents(linterp)\n",
    "y = model.decode(z_from_l)\n",
    "print(f'signal y.shape is {y.shape}') \n",
    "mix_signal = y[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(mix_signal)\n",
    "ipd.Audio(mix_signal, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b5184-cddf-48b6-bb57-6fcba2ad1439",
   "metadata": {},
   "source": [
    "### <font color='blue'> Now look at the histogram of the values in the latent variables (choose one in the next sell by assigning it to examinevector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9963e-896a-448e-93a9-28ca8a5d45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "examinevector=snd1_latents\n",
    "examinevector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18694f-73e8-4613-8018-804b003fcf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_value = torch.min(examinevector)\n",
    "largest_value = torch.max(examinevector)\n",
    "print(f\"The smallest value is {smallest_value.item()}\")\n",
    "print(f\"The largest value is {largest_value.item()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b13ad-ca8b-4261-953b-bda7aeca3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the tensor to 1D\n",
    "numpy_array = examinevector.cpu().detach().numpy().flatten()\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = 100\n",
    "\n",
    "# Create a histogram using NumPy to compute bin edges and counts\n",
    "hist, bin_edges = np.histogram(numpy_array, bins=num_bins)\n",
    "\n",
    "# Compute the average values for each bin\n",
    "bin_avg_values = []\n",
    "for i in range(num_bins):\n",
    "    mask = np.logical_and(numpy_array >= bin_edges[i], numpy_array <= bin_edges[i + 1])\n",
    "    bin_avg = np.mean(numpy_array[mask]) if np.sum(mask) > 0 else 0\n",
    "    bin_avg_values.append(bin_avg)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(numpy_array, bins=num_bins)\n",
    "plt.title('Histogram of 3D Tensor Values')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Calculate positions for the labels spread across the horizontal width of the image\n",
    "# label_positionsx = np.linspace(-num_bins/2, num_bins/2, num_bins)\n",
    "# label_positionsy = linspace_v(0, np.max(hist), num_bins)\n",
    "\n",
    "#print(label_positions)\n",
    "# Annotate the plot with average values, rotating labels 90 degrees clockwise\n",
    "for i in range(num_bins):\n",
    "    label = f'{bin_avg_values[i]:.2f}'\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f1f69-beb8-49b5-a033-9c94e4800461",
   "metadata": {},
   "outputs": [],
   "source": [
    "z,_,_ = model.quantizer.from_latents(snd2_latents)\n",
    "snd = model.decode(z) #z_from_l or z from encode are the same\n",
    "\n",
    "recon = snd[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(recon)\n",
    "ipd.Audio(recon, rate=44100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e55935-5db8-411d-97d6-e46060aa0402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
