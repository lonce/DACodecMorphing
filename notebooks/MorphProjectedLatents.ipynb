{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016cce63-8622-42e0-918c-ae0b2909b6b7",
   "metadata": {},
   "source": [
    "In this notebook, we are interpolating between sounds in the \"z\" domain - the space of the continuous latent space. The sounds are represented as a time series of latent vectors, to that means we are interpolating between different points in latent space at each point in time.  \n",
    "\n",
    "The results of this kind of interpolation in the latent space of the codec are not particularly interesting, and sound more like a cross fade (except for the amplitude variation which interpolates between the envelopes of the two sounds at each frame).  \n",
    "\n",
    "Still, it is interesting to see that the quantized space of the codec ( with (1024^9)^100 = 1024^900 = 10^1.8k is dense enough to handle this range of sounds and mixes with such ghigh fidelity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae02cc-68a1-4cb8-a5f8-10ed9f5b41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd /app\n",
    "\n",
    "import dac\n",
    "from audiotools import AudioSignal\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "\n",
    "#!pip install gputil\n",
    "#import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faae8f7-161b-4a4f-a655-b5e254bfb716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoryReport(msg, device) :\n",
    "    print(msg)\n",
    "    used_memory = torch.cuda.memory_allocated(device)\n",
    "    # Total memory managed by the caching allocator in bytes\n",
    "    reserved_memory = torch.cuda.memory_reserved(device)\n",
    "    print(f\"     Used memory on {device}: {used_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"     Reserved memory on {device}: {reserved_memory / 1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72176f9-2480-4b55-b2c2-115116e276c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()\n",
    "print(f'memeory on cuda 0 is  {torch.cuda.get_device_properties(0).total_memory/1e9}')\n",
    "print(f'memeory on cuda 1 is  { torch.cuda.get_device_properties(1).total_memory/1e9}')\n",
    "device = torch.device(\"cuda:0\") # if the docker was started with --gpus all, then can choose here.\n",
    "device\n",
    "memoryReport(\"Before we start: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163afb37-a4a6-42c5-a17b-550ff29b4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This always works, but takes longer (it is downloaded and cached):\n",
    "#model_path = dac.utils.download(model_type=\"44khz\") \n",
    "#if you already downloaded it locally:\n",
    "model_path = \"codecweights/weights_44_8.pth\"\n",
    "\n",
    "### This model doesn't sound as good - because it was trained on different data???\n",
    "# model_path = \"/scratch/codecs/codec.pth\" # /the default model from vampnet!\n",
    "\n",
    "model = dac.DAC.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af5bf5-5bb0-4a8c-bea8-a78672a033c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2edd162-6d33-47e0-a777-9e614a4f789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device); #wanna see the model? remove the semicolon\n",
    "model.eval()\n",
    "memoryReport(\"After loading model: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9eb41-d1f9-4b6a-9b7b-f2ab54d8943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot=\"dacdevdata\" \n",
    "# !ls {datadir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580143a4-4e02-4dfa-b55f-537b7c8f5b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datadir=dataroot+\"/44kHz/N4/PisWinAppBee_sparse_recon\"\n",
    "\n",
    "N_QUANTIZERS = 4  ## SEEMS TO HAVE NO EFFECT - I guess because it is a property of the pretrained model?\n",
    "\n",
    "snd1_wav ='/DSApplause--numClappers_exp-00.50.wav' \n",
    "#snd1_wav='/DSPistons--rate_exp-00.50.wav'\n",
    "snd2_wav = '/DSBugs--busybodyFreqFactor-00.50.wav'\n",
    "#snd2_wav ='/DSWind--strength-00.50.wav'\n",
    "\n",
    "CORTADOFACTURA=1  #cut the wavefile lengths by this amount before loading so we don't overrun GPU memory\n",
    "\n",
    "#1) LOAD A SOUND\n",
    "snd1 = AudioSignal(datadir + snd1_wav) # 2-second sound at 16kHz\n",
    "snd1 = snd1[0,0,: int(snd1.shape[2]/CORTADOFACTURA)] # cortado, otherwise the computation will bust memory\n",
    "\n",
    "#2) PUT IT ON THE GPU\n",
    "snd1.to(model.device)\n",
    "#3) PREPROCESS (make sure sr agrees with model, i guess)\n",
    "snd1_x = model.preprocess(snd1.audio_data, snd1.sample_rate)\n",
    "#4) ENCODE TO Z, C, and L\n",
    "\n",
    "with torch.no_grad():\n",
    "    snd1_z, snd1_codes, snd1_latents, _a, _b = model.encode(snd1_x, N_QUANTIZERS) #model.encode(snd1_x, 4)\n",
    "\n",
    "snd2 = AudioSignal(datadir + snd2_wav) # 2-second sound at 16kHz\n",
    "snd2 = snd2[0,0,: int(snd2.shape[2]/CORTADOFACTURA)] # cortado, otherwise the computation will bust memory\n",
    "\n",
    "snd2.to(model.device)\n",
    "snd2_x = model.preprocess(snd2.audio_data, snd2.sample_rate)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    snd2_z, snd2_codes, snd2_latents, _c, _d = model.encode(snd2_x, N_QUANTIZERS) # model.encode(snd2_x, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09c75a-d506-4a64-9fa0-ba999a8b1eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'snd1 Audio Signal is shape {snd1.shape}')\n",
    "print(f'snd1_z shape is: {snd1_z.shape}, and snd2_z shape is: {snd2_z.shape}')\n",
    "print(f'snd1_codes shape is: {snd1_codes.shape}, and snd2_codes shape is: {snd2_codes.shape}')\n",
    "print(f'snd1_latents shape is: {snd1_latents.shape}, and snd2_latents shape is: {snd2_latents.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1d698-a103-4b8d-9c2a-a5bf822b06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check a code vector to see if we are using the number specificied above\n",
    "snd1_codes[0,:,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6200c9-aa87-4613-bf12-d5fb1f5e2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del _a, _b, _c, _d\n",
    "del   snd1, snd2, snd1_x, snd2_x, snd1_codes, snd2_codes\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "memoryReport(\"After loading sounds: \", device) # how can ther be so much GPU memory used??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b1f49-54a8-49c6-9284-1fa1fbda50c4",
   "metadata": {},
   "source": [
    "<div style=\"height: 10px; background-color: blue;\"></div>\n",
    "This next cell is just for reporting a bug do Descript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd9307-f171-48c2-ae23-7da2f34dbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try to code the AudioSignal (snd1_x) with diffenent number of quantizers\n",
    "# foo1_z, foo1_c, _, _, _ = model.encode(snd1_x, n_quantizers=1)\n",
    "# foo4_z, foo4_c, _, _, _ = model.encode(snd1_x, n_quantizers=4)\n",
    "# fooN_z, fooN_c, _, _, _ = model.encode(snd1_x) # expected to use all 9 codebooks\n",
    "\n",
    "# print(f' Example code slices: \\n foo1_c: {foo1_c[0,:,40]} \\n foo4_c: {foo4_c[0,:,40]} \\n fooN_c: {fooN_c[0,:,40]}\\n')\n",
    "# print(f' And how about the z vectors that we will use to decode?\\n')\n",
    "# print(f' Are foo1_z and foo4_z tensors equal? Ans: {torch.equal(foo1_z, foo4_z)}')\n",
    "# print(f' Are foo1_z and fooN_z tensors equal? Ans: {torch.equal(foo1_z, fooN_z)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba94311e-151f-4d86-a185-9e3f387639ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Project Latents Experiment!!!!!!!!!!!!!!!!!\n",
    "### Lets just do a reality check that if we \"manually\" take the 8D latents to 1024D z and then decode, \n",
    "### it should be the same as the z we got from model encode.\n",
    "\n",
    "with torch.no_grad():\n",
    "    snd2_z_from_l,_a,_b = model.quantizer.from_latents(snd2_latents)\n",
    "print(f'snd2_z_from_l shape is: {snd2_z_from_l.shape}')\n",
    "torch.dist(snd2_z_from_l, snd2_z, p=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff48d1-7293-4a07-8ba7-5b0e84cb3d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "del _a,_b\n",
    "del snd2_z\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4582067-5a1a-4f37-ae47-5d5da0d3f1d7",
   "metadata": {},
   "source": [
    "### <font color='blue'> First decode both sounds frn 'z' space and play them </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ad0a1-1bae-4ce3-982d-c077cbc58711",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    snd2recon = model.decode(snd2_z_from_l) #z_from_l or z from encode are the same\n",
    "\n",
    "snd2reconsignal = snd2recon[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(snd2reconsignal)\n",
    "ipd.Audio(snd2reconsignal, rate=44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8e7d5-8f3a-4924-8d6c-6060cf152935",
   "metadata": {},
   "outputs": [],
   "source": [
    "del snd2_z_from_l, snd2recon\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b8fef4-897b-47a7-a441-f563d6bf1471",
   "metadata": {},
   "outputs": [],
   "source": [
    "memoryReport(\"After (trying) to free some chingada memory: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7dc6cb-cba4-44ad-ac59-88765adf4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    snd1recon = model.decode(snd1_z)\n",
    "\n",
    "snd1reconsignal = snd1recon[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(snd1reconsignal)\n",
    "ipd.Audio(snd1reconsignal, rate=44100)\n",
    "\n",
    "#original \n",
    "#snd1signal=snd1.audio_data.cpu().detach().numpy()[0,0,:]\n",
    "#plt.plot(snd1signal)\n",
    "#ipd.Audio(snd1signal, rate=44100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77502e0e-caac-4d86-ab80-06ad02505f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del  snd1recon, snd1_z\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aeb9e0-c7c0-49f5-ae1d-7094dbe5a560",
   "metadata": {},
   "source": [
    "### <font color='blue'> Now do n interpolation in the *latent* space (the latent space is the \"projected\" space and has only 8 dimensions for each codebook) </font>. Also note that below we are reconstructing from the low-D latent space, n ot 'z'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ed628-39f3-4801-a4ac-cb82d766c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"morph\" between two time-indexed sequences of latent variables\n",
    "# Interpoloates between i1*va+(1-i1)vb to i2*va+(1-i2)vb\n",
    "def sequentialinterp(va, vb, i1, i2) : \n",
    "    assert va.shape == vb.shape, \"Tensors must have the same shape\"\n",
    "    timesteps=va.shape[2]\n",
    "    linear_values = torch.linspace(i1, i2, timesteps, device=device)\n",
    "    complementlinear_values = 1-linear_values \n",
    "\n",
    "    return linear_values * va + complementlinear_values * vb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3ed75-146f-4ae3-8538-67c03434994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linterp=sequentialinterp(snd2_latents, snd1_latents, .6, .4)  ##Interpolate in the 8D projected space!\n",
    "print(f'linterp.shape is {linterp.shape}') \n",
    "\n",
    "# first from low-D (8 per codebook) to 1024\n",
    "with torch.no_grad():\n",
    "    z_from_l,_a,_b = model.quantizer.from_latents(linterp)\n",
    "\n",
    "#now from 1024 z space to audio\n",
    "with torch.no_grad():\n",
    "    y = model.decode(z_from_l)\n",
    "\n",
    "print(f'signal y.shape is {y.shape}') \n",
    "mix_signal = y[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(mix_signal)\n",
    "ipd.Audio(mix_signal, rate=44100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea21e711-bb40-4e69-bdff-5e86ac24549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del z_from_l, _a, _b, y\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb8686-b19d-49a3-b283-2f0d35d865c4",
   "metadata": {},
   "source": [
    "### <font color='blue'> Now rather than interpolating in latent space, swap value in the dimensions with even index. Each sound is now made up of latents where half the values come from one sound, half the values from the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e5f1a-c6da-4f1f-b765-2008500b1908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the latent variable at each time step, \n",
    "#and swaps their invidual values in the dimensions with an even index\n",
    "# Thus each matrix at each time step has half its values from one sound,\n",
    "# and the other half from the other. \n",
    "\n",
    "# does this in place - modifies the original matrices\n",
    "def swap_elements_for_even_n(matrix1, matrix2):\n",
    "    # Get the shape of the input matrices\n",
    "    _, n, m = matrix1.size()\n",
    "\n",
    "    del _\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Create masks for even and odd indices along the n dimension\n",
    "    even_mask = torch.arange(n) % 2 == 1  # Indices where n is even\n",
    "    odd_mask = torch.arange(n) % 2 == 0   # Indices where n is odd\n",
    "\n",
    "    # Select elements where n is even from both matrices\n",
    "    even_elements_matrix1 = matrix1[:, even_mask, :]\n",
    "    even_elements_matrix2 = matrix2[:, even_mask, :]\n",
    "\n",
    "    # Swap the even elements between the matrices\n",
    "    matrix1[:, even_mask, :] = even_elements_matrix2\n",
    "    matrix2[:, even_mask, :] = even_elements_matrix1\n",
    "\n",
    "    return matrix1, matrix2\n",
    "\n",
    "## test\n",
    "# a= torch.rand(1, 4, 2)\n",
    "# b= torch.rand(1, 4, 2)\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print('--------')\n",
    "# swap_elements_for_even_n(a, b)\n",
    "# print(a)\n",
    "# print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c64a7f-4391-42bd-bd3e-63932b2c2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "la=snd2_latents\n",
    "lb=snd1_latents\n",
    "# first do a swap of values in the latent space for even-numbered dimensions\n",
    "la, lb = swap_elements_for_even_n(la, lb)\n",
    "linterp=sequentialinterp(la, lb, 0, 0)  ## (0,0 plays the first sound only, 1,1 plays the second sound only)\n",
    "print(f'linterp.shape is {linterp.shape}') \n",
    "\n",
    "with torch.no_grad():\n",
    "    z_from_l,_c,_d = model.quantizer.from_latents(linterp)\n",
    "    y = model.decode(z_from_l)\n",
    "print(f'signal y.shape is {y.shape}') \n",
    "mix_signal = y[0,0,:].cpu().detach().numpy()\n",
    "plt.plot(mix_signal)\n",
    "ipd.Audio(mix_signal, rate=44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645daa1b-9a43-4f04-87a3-0d2c372e6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "del  _c,_d, z_from_l, la, lb, linterp\n",
    "del snd1_latents, snd2_latents\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f896b-b8e2-4c73-a635-f60ee26f3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "memoryReport(\"...: \", device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
