{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf7c208-29f2-4d33-8e0f-02887762ba56",
   "metadata": {},
   "source": [
    "### <font color='blue'> In this notebook, we want to look at the histogram of latent vector component values for the Koray dataset (this dataset isn't distributed with the repository - just create a folder of wav files yourself to see the deistribution of latent vector values. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06459916-4bc3-410d-812d-7632f344c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd /app\n",
    "\n",
    "import dac\n",
    "from audiotools import AudioSignal\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import soundfile as sf\n",
    "# import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8cbbc7-06cc-4c6a-8fac-ed05421bf146",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()\n",
    "print(f'memeory on cuda 0 is  {torch.cuda.get_device_properties(0).total_memory/1e9}')\n",
    "print(f'memeory on cuda 1 is  { torch.cuda.get_device_properties(1).total_memory/1e9}')\n",
    "device = torch.device(\"cuda:0\") # if the docker was started with --gpus all, then can choose here.\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3a06c-a7cb-4f5d-a822-be7ce662bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you haven't downloaded the model weights ahead of time, just do this:\n",
    "# model_path = dac.utils.download(model_type=\"44khz\")\n",
    "model_path = \"codecweights/weights_44_8.pth\"\n",
    "#model_path = \"codecweights/weights_16_8.pth\"\n",
    "\n",
    "\n",
    "model = dac.DAC.load(model_path)\n",
    "model.to(device); #wanna see the model? remove the semicolon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388006a-9b98-4f37-b49d-b68fdb51f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir=\"/scratch/lonce/koraySegmentedSoundData/split_1sec_44k\"\n",
    "\n",
    "N_QUANTIZERS = 9  ## SEEMS TO HAVE NO EFFECT - I guess because it is a property of the pretrained model?\n",
    "\n",
    "snd1_wav ='/file0791_segment35.wav' \n",
    "\n",
    "#1) LOAD A SOUND\n",
    "snd1 = AudioSignal(datadir + snd1_wav) # 2-second sound at 16kHz\n",
    "#snd1 = snd1[0,0,: int(snd1.shape[2]/CORTADOFACTURA)] # cortado, otherwise the computation will bust memory\n",
    "\n",
    "#2) PUT IT ON THE GPU\n",
    "snd1.to(model.device)\n",
    "#3) PREPROCESS (make sure sr agrees with model, i guess)\n",
    "snd1_x = model.preprocess(snd1.audio_data, snd1.sample_rate)\n",
    "#4) ENCODE TO Z, C, and L\n",
    "with torch.no_grad():\n",
    "    snd1_z, snd1_codes, snd1_latents, _a, _b = model.encode(snd1_x, N_QUANTIZERS) #model.encode(snd1_x, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2271e-73ac-409c-9abe-023566a675d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'snd1_latents shape is: {snd1_latents.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e9b222-e1e6-45bf-b6e2-8a5d9ff21814",
   "metadata": {},
   "outputs": [],
   "source": [
    "ydim=snd1_latents.shape[1]\n",
    "xdim=snd1_latents.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269e172-b1ba-44a7-8a11-9352e9e5a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that we are not useing *any* of these anymore, so clean up memory so notebook can be rerun without having to restart the damn kernel.\n",
    "del snd1_z, snd1_codes, snd1_latents, _a, _b\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84978996-5261-48aa-9f65-68e702b6ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "# def anal(wav_data):\n",
    "#     # Dummy implementation of the analysis function\n",
    "#     # Replace with your actual analysis logic\n",
    "#     return np.array([np.mean(wav_data), np.std(wav_data)])\n",
    "\n",
    "def read_random_wav_files(folder, n, ilow=0, ihi=72):\n",
    "    # List all .wav files in the folder\n",
    "    files = [f for f in os.listdir(folder) if f.endswith('.wav')]\n",
    "\n",
    "    \n",
    "    # Select n random files\n",
    "    random_files = random.sample(files, min(n, len(files)))\n",
    "\n",
    "\n",
    "    # Array to store the concatenated results\n",
    "    results = []\n",
    "\n",
    "    for file in random_files:\n",
    "        # Read the wav file\n",
    "        asig = AudioSignal(datadir + \"/\" + file)\n",
    "        asig.to(model.device)\n",
    "        asig_x = model.preprocess(asig.audio_data, asig.sample_rate)\n",
    "        with torch.no_grad():\n",
    "           _a, _b, asig_latents, _c, _d = model.encode(asig_x) \n",
    "\n",
    "        #clean up GPU memory\n",
    "        del  _a, _b, _c, _d\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        results.append(asig_latents[0,ilow:ihi, :])\n",
    "        \n",
    "    return torch.stack(results)\n",
    "    # # Concatenate all results into a tensor\n",
    "    # result_tensor = np.vstack(results)\n",
    "\n",
    "    # return result_tensor\n",
    "\n",
    "# # Example usage\n",
    "# folder_path = '/path/to/your/wav/files'\n",
    "# n = 5  # Number of random files to read\n",
    "# result_tensor = read_random_wav_files(folder_path, n)\n",
    "# print(result_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051adc42-568b-4da7-af9f-9474c6ec42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_tensor = read_random_wav_files(datadir, 100,64,72)\n",
    "# result_tensor = read_random_wav_files(datadir, 100,0,8)\n",
    "result_tensor = read_random_wav_files(datadir, 100)\n",
    "\n",
    "print(f'result_tensor shape is: {result_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf75604-2df2-472a-983e-7b04480ea796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the tensor to 1D\n",
    "numpy_array = result_tensor.cpu().detach().numpy().flatten()\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = 25\n",
    "\n",
    "# Create a histogram using NumPy to compute bin edges and counts\n",
    "hist, bins = np.histogram(numpy_array, bins=num_bins, range=(-12,12))\n",
    "\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(bins[:-1], bins, weights=hist)\n",
    "plt.title('Histogram of 3D Tensor Values')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Calculate positions for the labels spread across the horizontal width of the image\n",
    "# label_positionsx = np.linspace(-num_bins/2, num_bins/2, num_bins)\n",
    "# label_positionsy = linspace_v(0, np.max(hist), num_bins)\n",
    "\n",
    "# #print(label_positions)\n",
    "# # Annotate the plot with average values, rotating labels 90 degrees clockwise\n",
    "# for i in range(num_bins):\n",
    "#     label = f'{bin_avg_values[i]:.2f}'\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914fa4d4-985f-4a35-9a37-02e14d067bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
